{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r\"C:\\Users\\ungdu\\Downloads\\Chat_Mini\\mini_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được xử lý và lưu vào processed_data.csv\n",
      "Dữ liệu đã được xử lý và lưu vào chunked_data.csv\n",
      "Embedding đã được lưu vào embedding_data.csv\n",
      "Batch 1/1\n",
      "{'chunk': 'trường đại học công nghệ thông tin dhqg tp.hcm được thành lập từ khi nào?', 'Question': 'trường đại học công nghệ thông tin dhqg tp.hcm được thành lập từ khi nào?', 'Answer': 'trường đại học công nghệ thông tin dhqg tp.hcm được thành lập từ ngày 8 tháng 6 năm 2006. trường đại học công nghệ thông tin uit đại học quốc gia thành phố hồ chí minh được thành lập vào ngày 8 tháng 6 năm 2006 theo quyết định của thủ tướng chính phủ.'}\n",
      "{'chunk': 'trường uit đại học công nghệ thông tin dhqg tp.hcm có những thành tựu gì nổi bật trong lĩnh vực đào tạo?', 'Question': 'trường uit đại học công nghệ thông tin dhqg tp.hcm có những thành tựu gì nổi bật trong lĩnh vực đào tạo?', 'Answer': 'trường đại học công nghệ thông tin uit đã đạt được nhiều thành tựu nổi bật trong lĩnh vực đào tạo bao gồm chất lượng đào tạo uit luôn nằm trong top các trường đại học hàng đầu về công nghệ thông tin tại việt nam. chương trình đào tạo của trường được thiết kế theo chuẩn quốc tế giúp sinh viên có kiến thức vững vàng và kỹ năng thực tiễn. giải thưởng và thành tích sinh viên uit thường xuyên đạt giải cao trong các cuộc thi quốc gia và quốc tế như olympic tin học acm icpc và các cuộc thi về an ninh mạng. hợp tác quốc tế uit có nhiều chương trình hợp tác với các trường đại học và tổ chức quốc tế giúp sinh viên có cơ hội học tập và nghiên cứu ở nước ngoài. cơ sở vật chất hiện đại trường đầu tư mạnh vào cơ sở vật chất phòng thí nghiệm và các trang thiết bị hiện đại để hỗ trợ quá trình học tập và nghiên cứu của sinh viên. đội ngũ giảng viên uit có đội ngũ giảng viên giàu kinh nghiệm nhiều người trong số họ đã từng học tập và làm việc tại các trường đại học danh tiếng trên thế giới.'}\n",
      "{'chunk': 'trường uit có xếp hạng như thế nào ở việt nam?', 'Question': 'trường uit có xếp hạng như thế nào ở việt nam?', 'Answer': 'trường uit có xếp hạng ở việt nam rất tốt. trường đại học công nghệ thông tin uit đại học quốc gia thành phố hồ chí minh thường xuyên nằm trong top các trường đại học hàng đầu về đào tạo công nghệ thông tin tại việt nam. theo một số bảng xếp hạng gần đây uit được đánh giá cao nhờ chất lượng đào tạo cơ sở vật chất hiện đại và đội ngũ giảng viên giàu kinh nghiệm. cụ thể uit thường được xếp vào top 3 hoặc top 5 các trường đại học tốt nhất về công nghệ thông tin tại việt nam cùng với các trường như đại học bách khoa hà nội và đại học công nghệ thông tin đại học quốc gia hà nội'}\n",
      "{'chunk': 'trường uit có liên kết với các tổ chức hay doanh nghiệp lớn trong ngành cntt không?', 'Question': 'trường uit có liên kết với các tổ chức hay doanh nghiệp lớn trong ngành cntt không?', 'Answer': 'trường uit có liên kết với các tổ chức hay doanh nghiệp lớn trong ngành cntt. trường đại học công nghệ thông tin uit có mối quan hệ hợp tác chặt chẽ với nhiều tổ chức và doanh nghiệp lớn trong ngành công nghệ thông tin. một số đối tác tiêu biểu bao gồm microsoft uit hợp tác với microsoft trong nhiều dự án nghiên cứu và phát triển công nghệ cũng như tổ chức các khóa đào tạo và hội thảo chuyên ngành. ibm trường có các chương trình hợp tác với ibm trong việc đào tạo và cung cấp các giải pháp công nghệ tiên tiến. fpt software sinh viên uit thường xuyên tham gia thực tập và làm việc tại fpt software một trong những công ty công nghệ hàng đầu tại việt nam. vng corporation uit hợp tác với vng trong nhiều dự án nghiên cứu và phát triển cũng như cung cấp cơ hội thực tập và việc làm cho sinh viên. vnpt trường cũng có mối quan hệ hợp tác với tập đoàn bưu chính viễn thông việt nam vnpt trong các dự án nghiên cứu và phát triển công nghệ thông tin và truyền thông. những mối quan hệ hợp tác này không chỉ giúp nâng cao chất lượng đào tạo mà còn tạo điều kiện cho sinh viên tiếp cận với môi trường làm việc thực tế và các cơ hội nghề nghiệp sau khi tốt nghiệp.'}\n",
      "{'chunk': 'sứ mệnh của trường đại học công nghệ thông tin uit là gì?', 'Question': 'sứ mệnh của trường đại học công nghệ thông tin uit là gì?', 'Answer': 'sứ mệnh của trường đại học công nghệ thông tin uit đại học quốc gia thành phố hồ chí minh là đào tạo nhân lực chất lượng cao cung cấp nguồn nhân lực có trình độ chuyên môn cao kỹ năng thực tiễn vững vàng đáp ứng nhu cầu của thị trường lao động trong và ngoài nước. nghiên cứu khoa học và chuyển giao công nghệ thực hiện các nghiên cứu khoa học tiên tiến và chuyển giao công nghệ trong lĩnh vực công nghệ thông tin và truyền thông góp phần vào sự phát triển của ngành và xã hội. hợp tác quốc tế mở rộng hợp tác với các tổ chức doanh nghiệp và trường đại học quốc tế để nâng cao chất lượng đào tạo và nghiên cứu. phát triển toàn diện sinh viên tạo môi trường học tập và rèn luyện toàn diện giúp sinh viên phát triển cả về kiến thức kỹ năng và phẩm chất cá nhân. uit luôn hướng tới việc trở thành một trung tâm hàng đầu về đào tạo và nghiên cứu trong lĩnh vực công nghệ thông tin góp phần vào sự phát triển bền vững của đất nước.'}\n",
      "{'chunk': 'tầm nhìn phát triển của trường uit trong những năm 2025 như thế nào?', 'Question': 'tầm nhìn phát triển của trường uit trong những năm 2025 như thế nào?', 'Answer': 'tầm nhìn phát triển của trường đại học công nghệ thông tin uit trong những năm tới bao gồm trở thành trung tâm hàng đầu về đào tạo và nghiên cứu uit đặt mục tiêu trở thành một trong những trường đại học hàng đầu khu vực đông nam á về đào tạo và nghiên cứu trong lĩnh vực công nghệ thông tin và truyền thông. nâng cao chất lượng đào tạo tiếp tục cải tiến chương trình đào tạo theo chuẩn quốc tế tăng cường hợp tác với các doanh nghiệp và tổ chức quốc tế để đảm bảo sinh viên có kiến thức và kỹ năng đáp ứng nhu cầu thị trường lao động. phát triển nghiên cứu khoa học đẩy mạnh các hoạt động nghiên cứu khoa học đặc biệt là trong các lĩnh vực công nghệ mới như trí tuệ nhân tạo ai dữ liệu lớn big data và an ninh mạng. tăng cường hợp tác quốc tế mở rộng hợp tác với các trường đại học và tổ chức quốc tế tạo điều kiện cho sinh viên và giảng viên tham gia các chương trình trao đổi nghiên cứu và học tập ở nước ngoài. phát triển cơ sở vật chất đầu tư vào cơ sở vật chất hiện đại xây dựng các phòng thí nghiệm tiên tiến và môi trường học tập thân thiện sáng tạo. hỗ trợ sinh viên toàn diện tạo môi trường học tập và rèn luyện toàn diện hỗ trợ sinh viên phát triển cả về kiến thức kỹ năng và phẩm chất cá nhân giúp họ tự tin và sẵn sàng cho tương lai.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import uuid\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Hàm xóa ký tự đặc biệt\n",
    "def remove_special_characters(text):\n",
    "    text = re.sub(r'<.*?>', ' ', text)  # Loại bỏ HTML tags\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!\\*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', text)  # Loại bỏ URL\n",
    "    text = re.sub(r'[^\\w\\s.!?@]', ' ', text)  # Loại bỏ ký tự đặc biệt\n",
    "    return text\n",
    "\n",
    "# Hàm chuyển chữ về chữ thường\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Hàm loại bỏ khoảng trắng thừa\n",
    "def remove_extra_whitespaces(text):\n",
    "    text = text.strip()  # Xóa khoảng trắng đầu và cuối\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Xóa khoảng trắng thừa trong chuỗi\n",
    "    return text\n",
    "\n",
    "# Hàm tổng hợp để tiền xử lý văn bản\n",
    "def preprocess_text(text):\n",
    "    text = lowercase(text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_extra_whitespaces(text)\n",
    "    return text\n",
    "\n",
    "# Hàm xóa các dòng trùng lặp dựa trên một cột cụ thể\n",
    "def remove_duplicate_rows(df, column_name):\n",
    "    df.drop_duplicates(subset=column_name, keep='first', inplace=True)\n",
    "    return df\n",
    "\n",
    "# Hàm tính TF-IDF cho toàn bộ cột \"Câu hỏi\"\n",
    "def calculate_tfidf(data, column_name):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(data[column_name].dropna().tolist())\n",
    "\n",
    "    # Lưu TF-IDF vào file CSV\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out(), index=data[column_name].dropna())\n",
    "    tfidf_df.to_csv(\"tfidf_values.csv\", index=True)\n",
    "\n",
    "    return tfidf_matrix\n",
    "\n",
    "# Hàm chunking semantic để chia đoạn văn\n",
    "class SemanticChunker:\n",
    "    def __init__(self, threshold=0.3):\n",
    "        self.threshold = threshold\n",
    "        nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "    def embed_function(self, sentences):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform(sentences).toarray()\n",
    "        return vectors\n",
    "\n",
    "    def split_text(self, text):\n",
    "        sentences = nltk.sent_tokenize(text)  # Tách câu\n",
    "        sentences = [item for item in sentences if item and item.strip()]\n",
    "        if not sentences:\n",
    "            return []\n",
    "\n",
    "        vectors = self.embed_function(sentences)\n",
    "        similarities = cosine_similarity(vectors)\n",
    "\n",
    "        # Lưu cosine similarity vào file CSV\n",
    "        cosine_df = pd.DataFrame(similarities, index=sentences, columns=sentences)\n",
    "        cosine_df.to_csv(\"cosine_similarity.csv\", index=True)\n",
    "\n",
    "        chunks = [[sentences[0]]]  # Bắt đầu chunk đầu tiên\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim_score = similarities[i-1, i]\n",
    "            if sim_score >= self.threshold:\n",
    "                chunks[-1].append(sentences[i])\n",
    "            else:\n",
    "                chunks.append([sentences[i]])\n",
    "\n",
    "        return [' '.join(chunk) for chunk in chunks]\n",
    "\n",
    "# Hàm chia DataFrame thành các batch\n",
    "def divide_dataframe(df, batch_size):\n",
    "    return [df.iloc[i:i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "\n",
    "# Đọc file CSV đầu vào\n",
    "input_file = r\"C:\\Users\\ungdu\\Downloads\\Chat_Mini\\mini_data.csv\"\n",
    "output_file = \"processed_data.csv\"\n",
    "chunked_file = \"chunked_data.csv\"\n",
    "embedding_file = \"embedding_data.csv\"\n",
    "\n",
    "try:\n",
    "    # Đọc dữ liệu từ file CSV\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Kiểm tra nếu DataFrame không rỗng\n",
    "    if not df.empty:\n",
    "        # Tiền xử lý cột \"Câu hỏi\"\n",
    "        if 'Câu hỏi' in df.columns and 'Câu trả lời' in df.columns:\n",
    "            df['Câu hỏi'] = df['Câu hỏi'].apply(preprocess_text)\n",
    "            df['Câu trả lời'] = df['Câu trả lời'].apply(preprocess_text)\n",
    "\n",
    "        # Xóa các dòng trùng lặp dựa trên cột 'Câu hỏi' nếu tồn tại\n",
    "        if 'Câu hỏi' in df.columns and 'Câu trả lời' in df.columns:\n",
    "            df = remove_duplicate_rows(df, 'Câu hỏi')\n",
    "            df = remove_duplicate_rows(df, 'Câu trả lời')\n",
    "\n",
    "        # Lưu dữ liệu đã tiền xử lý ra file mới\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Dữ liệu đã được xử lý và lưu vào {output_file}\")\n",
    "\n",
    "        # Tính TF-IDF cho cột \"Câu hỏi\"\n",
    "        tfidf_matrix = calculate_tfidf(df, 'Câu hỏi')\n",
    "\n",
    "        # Chunking dữ liệu\n",
    "        chunker = SemanticChunker(threshold=0.3)\n",
    "        chunk_records = []  # Danh sách chứa các bản ghi mới với từng chunk\n",
    "\n",
    "        if 'Câu hỏi' in df.columns:\n",
    "            for _, row in df.iterrows():\n",
    "                selected_text = row['Câu hỏi']\n",
    "                if isinstance(selected_text, str) and selected_text.strip():\n",
    "                    # Gọi hàm chunking\n",
    "                    chunks = chunker.split_text(selected_text)\n",
    "                    # Lặp qua từng chunk và tạo bản ghi mới\n",
    "                    for chunk in chunks:\n",
    "                        new_record = row.to_dict()\n",
    "                        new_record['chunk'] = chunk  # Thêm chunk vào bản ghi\n",
    "                        chunk_records.append(new_record)\n",
    "\n",
    "        # Tạo DataFrame mới từ các bản ghi đã mở rộng chunk\n",
    "        chunked_df = pd.DataFrame(chunk_records)\n",
    "\n",
    "        # Lưu dữ liệu đã chunking ra file mới\n",
    "        chunked_df.to_csv(chunked_file, index=False)\n",
    "        print(f\"Dữ liệu đã được xử lý và lưu vào {chunked_file}\")\n",
    "\n",
    "        # Embedding dữ liệu\n",
    "        embedding_model = SentenceTransformer('keepitreal/vietnamese-sbert')\n",
    "\n",
    "        # Tính toán embedding từ cột chunk trong chunked_df\n",
    "        chunked_df['embedding'] = chunked_df['chunk'].apply(\n",
    "            lambda x: embedding_model.encode(x) if isinstance(x, str) else None\n",
    "        )\n",
    "\n",
    "        # Lưu embedding ra file CSV\n",
    "        chunked_df.to_csv(embedding_file, index=False)\n",
    "        print(f\"Embedding đã được lưu vào {embedding_file}\")\n",
    "\n",
    "        # Kết nối với Chroma và lưu dữ liệu theo batch\n",
    "        client = chromadb.PersistentClient(\"db\")\n",
    "        collection = client.get_or_create_collection(\"embeddings_collection\")\n",
    "        batch_size = 256\n",
    "        batches = divide_dataframe(chunked_df, batch_size)\n",
    "\n",
    "        for i, batch in enumerate(batches):\n",
    "            ids = [str(uuid.uuid4()) for _ in range(len(batch))]\n",
    "            documents = batch['chunk'].tolist()\n",
    "            embeddings = batch['embedding'].tolist()\n",
    "            metadatas = [\n",
    "                {\n",
    "                    \"chunk\": chunk,\n",
    "                    \"Question\": question,\n",
    "                    \"Answer\": answer\n",
    "                }\n",
    "                for chunk, question, answer in zip(batch['chunk'], batch['Câu hỏi'], batch['Câu trả lời'])\n",
    "            ]\n",
    "\n",
    "            collection.add(\n",
    "                ids=ids,\n",
    "                documents=documents,\n",
    "                embeddings=embeddings,\n",
    "                metadatas=metadatas\n",
    "            )\n",
    "\n",
    "            # Hiển thị metadata trong batch\n",
    "            print(f\"Batch {i + 1}/{len(batches)}\")\n",
    "            for metadata in metadatas:\n",
    "                print(metadata)\n",
    "\n",
    "    else:\n",
    "        print(\"Dữ liệu đầu vào rỗng!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Không tìm thấy file {input_file}!\")\n",
    "except Exception as e:\n",
    "    print(f\"Đã xảy ra lỗi: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension matches expected size.\n",
      "--- ChromaDB Search Results ---\n",
      "\n",
      "1) Distance: 83.5368 Chunk: trường uit đại học công nghệ thông tin dhqg tp.hcm có những thành tựu gì nổi bật trong lĩnh vực đào tạo? Question: trường uit đại học công nghệ thông tin dhqg tp.hcm có những thành tựu gì nổi bật trong lĩnh vực đào tạo? Answer: trường đại học công nghệ thông tin uit đã đạt được nhiều thành tựu nổi bật trong lĩnh vực đào tạo bao gồm chất lượng đào tạo uit luôn nằm trong top các trường đại học hàng đầu về công nghệ thông tin tại việt nam. chương trình đào tạo của trường được thiết kế theo chuẩn quốc tế giúp sinh viên có kiến thức vững vàng và kỹ năng thực tiễn. giải thưởng và thành tích sinh viên uit thường xuyên đạt giải cao trong các cuộc thi quốc gia và quốc tế như olympic tin học acm icpc và các cuộc thi về an ninh mạng. hợp tác quốc tế uit có nhiều chương trình hợp tác với các trường đại học và tổ chức quốc tế giúp sinh viên có cơ hội học tập và nghiên cứu ở nước ngoài. cơ sở vật chất hiện đại trường đầu tư mạnh vào cơ sở vật chất phòng thí nghiệm và các trang thiết bị hiện đại để hỗ trợ quá trình học tập và nghiên cứu của sinh viên. đội ngũ giảng viên uit có đội ngũ giảng viên giàu kinh nghiệm nhiều người trong số họ đã từng học tập và làm việc tại các trường đại học danh tiếng trên thế giới.\n",
      "\n",
      "2) Distance: 108.0613 Chunk: trường đại học công nghệ thông tin dhqg tp.hcm được thành lập từ khi nào? Question: trường đại học công nghệ thông tin dhqg tp.hcm được thành lập từ khi nào? Answer: trường đại học công nghệ thông tin dhqg tp.hcm được thành lập từ ngày 8 tháng 6 năm 2006. trường đại học công nghệ thông tin uit đại học quốc gia thành phố hồ chí minh được thành lập vào ngày 8 tháng 6 năm 2006 theo quyết định của thủ tướng chính phủ.\n",
      "\n",
      "\n",
      "--- HYDE Search Results ---\n",
      "Hypothetical Documents: []\n",
      "No hypothetical documents generated. Skipping HYDE search.\n",
      "No hypothetical documents generated.\n",
      "\n",
      "--- Final Answer Generated by Gemini ---\n",
      "Chất lượng đào tạo tại UIT được đánh giá rất cao, nằm trong top các trường đại học hàng đầu về công nghệ thông tin tại Việt Nam. Chương trình đào tạo được thiết kế theo chuẩn quốc tế, giúp sinh viên có kiến thức vững vàng và kỹ năng thực tiễn.  Sinh viên UIT thường xuyên đạt giải cao trong các cuộc thi quốc gia và quốc tế.\n",
      "\n",
      "Về cơ sở vật chất, UIT đầu tư mạnh vào phòng thí nghiệm và các trang thiết bị hiện đại để hỗ trợ quá trình học tập và nghiên cứu của sinh viên.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure Generative AI\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyAgOBMLyULtQE6PBI6u6v-bawhlF3UkhNI\"\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "modelai = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Load SentenceTransformer model\n",
    "encoder_model = SentenceTransformer('keepitreal/vietnamese-sbert')\n",
    "\n",
    "# Connect to ChromaDB\n",
    "client = chromadb.PersistentClient(\"db\")\n",
    "collection = client.get_or_create_collection(\"embeddings_collection\")\n",
    "\n",
    "# Verify collection embedding dimension\n",
    "def verify_embedding_dimension(collection, expected_dimension=768):\n",
    "    try:\n",
    "        # Generate a dummy embedding to verify\n",
    "        dummy_embedding = [0.0] * expected_dimension\n",
    "        collection.query(query_embeddings=[dummy_embedding], n_results=1)\n",
    "        print(\"Embedding dimension matches expected size.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Embedding dimension verification failed. Details: {str(e)}\")\n",
    "\n",
    "# Define vector search function\n",
    "def vector_search(query, collection, columns_to_answer, number_docs_retrieval=2):\n",
    "    query_embeddings = encoder_model.encode([query])  # Ensure embeddings are in the correct dimension\n",
    "\n",
    "    if isinstance(query_embeddings, np.ndarray):\n",
    "        if query_embeddings.shape[1] != 768:\n",
    "            raise ValueError(f\"Query embedding dimension {query_embeddings.shape[1]} does not match required dimension 768.\")\n",
    "        query_embeddings = query_embeddings.tolist()  # Convert numpy array to list\n",
    "\n",
    "    search_results = collection.query(\n",
    "        query_embeddings=query_embeddings,\n",
    "        n_results=number_docs_retrieval\n",
    "    )\n",
    "\n",
    "    metadatas = search_results['metadatas']\n",
    "    scores = search_results['distances']\n",
    "\n",
    "    search_result = \"\"\n",
    "    for i, (meta, score) in enumerate(zip(metadatas[0], scores[0]), start=1):\n",
    "        search_result += f\"\\n{i}) Distance: {score:.4f}\"\n",
    "        for column in columns_to_answer:\n",
    "            if column in meta:\n",
    "                search_result += f\" {column.capitalize()}: {meta.get(column)}\"\n",
    "        search_result += \"\\n\"\n",
    "\n",
    "    return metadatas, search_result\n",
    "\n",
    "# Define HYDE-based search function\n",
    "def generate_hypothetical_documents(model, query, num_samples=10):\n",
    "    hypothetical_docs = []\n",
    "    for _ in range(num_samples):\n",
    "        enhanced_prompt = f\"Write a paragraph that answers the question: {query}\"\n",
    "        response = model.generate_content(enhanced_prompt)\n",
    "        if hasattr(response, 'content'):\n",
    "            hypothetical_docs.append(response.content)\n",
    "    return hypothetical_docs\n",
    "\n",
    "def encode_hypothetical_documents(documents, encoder_model):\n",
    "    if not documents:\n",
    "        raise ValueError(\"No hypothetical documents generated. Cannot encode empty documents.\")\n",
    "\n",
    "    embeddings = [encoder_model.encode(doc) for doc in documents]  # Corrected dimension issue\n",
    "    avg_embedding = np.mean(embeddings, axis=0)\n",
    "\n",
    "    if isinstance(avg_embedding, np.ndarray):\n",
    "        if avg_embedding.shape[0] != 768:\n",
    "            raise ValueError(f\"Aggregated embedding dimension {avg_embedding.shape[0]} does not match required dimension 768.\")\n",
    "        avg_embedding = avg_embedding.tolist()  # Convert numpy array to list\n",
    "\n",
    "    return [avg_embedding]  # Return as a list of one embedding\n",
    "\n",
    "def hyde_search(encoder_model, query, collection, columns_to_answer, number_docs_retrieval=2, num_samples=2):\n",
    "    hypothetical_documents = generate_hypothetical_documents(modelai, query, num_samples)\n",
    "\n",
    "    print(\"Hypothetical Documents:\", hypothetical_documents)\n",
    "\n",
    "    if not hypothetical_documents:\n",
    "        print(\"No hypothetical documents generated. Skipping HYDE search.\")\n",
    "        return [], \"No hypothetical documents generated.\"\n",
    "\n",
    "    # Encode the hypothetical documents into embeddings\n",
    "    aggregated_embedding = encode_hypothetical_documents(hypothetical_documents, encoder_model)\n",
    "\n",
    "    # Perform the search on the collection with the generated embeddings\n",
    "    search_results = collection.query(\n",
    "        query_embeddings=aggregated_embedding,\n",
    "        n_results=number_docs_retrieval\n",
    "    )\n",
    "\n",
    "    search_result = \"\"\n",
    "    metadatas = search_results['metadatas']\n",
    "\n",
    "    # Format the search results\n",
    "    for i, meta in enumerate(metadatas[0], start=1):\n",
    "        search_result += f\"\\n{i})\"\n",
    "        for column in columns_to_answer:\n",
    "            if column in meta:\n",
    "                search_result += f\" {column.capitalize()}: {meta.get(column)}\"\n",
    "        search_result += \"\\n\"\n",
    "\n",
    "    return metadatas, search_result\n",
    "\n",
    "# Verify embedding dimension\n",
    "verify_embedding_dimension(collection)\n",
    "\n",
    "# Test the search methods\n",
    "prompt = \"Ngành Thương mại Điện tử có điểm chuẩn năm 2024 \"\n",
    "columns_to_select = [\"chunk\", \"Question\", \"Answer\"]  # Các cột cần lấy dữ liệu\n",
    "# columns_to_select = [col for col in chunked_df.columns if col != 'chunk'] \n",
    "\n",
    "# Search using Chroma\n",
    "print(\"--- ChromaDB Search Results ---\")\n",
    "metadatas_chroma, result_chroma = vector_search(prompt, collection, columns_to_select)\n",
    "print(result_chroma)\n",
    "\n",
    "# Search using HYDE and Gemini\n",
    "print(\"\\n--- HYDE Search Results ---\")\n",
    "metadatas_hyde, result_hyde = hyde_search(encoder_model, prompt, collection, columns_to_select)\n",
    "print(result_hyde)\n",
    "\n",
    "# Generate enhanced prompt\n",
    "retrieved_data = result_chroma + \"\\n\" + result_hyde\n",
    "enhanced_prompt = f\"Câu hỏi của người dùng là: \\\"{prompt}\\\". Trả lời câu hỏi của người dùng dựa trên các dữ liệu sau: \\n{retrieved_data}\"\n",
    "\n",
    "# Generate final answer\n",
    "print(\"\\n--- Final Answer Generated by Gemini ---\")\n",
    "response = modelai.generate_content(enhanced_prompt)\n",
    "if hasattr(response, 'text'):\n",
    "    print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
